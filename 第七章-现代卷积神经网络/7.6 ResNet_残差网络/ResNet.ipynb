{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042c86e3",
   "metadata": {},
   "source": [
    "# ResNet\n",
    "使用ResNet来对Fasion MNIST数据集进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aba930",
   "metadata": {},
   "source": [
    "## 1 加载相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16034e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from IPython import display\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47476705",
   "metadata": {},
   "source": [
    "## 2 自定义Restidual类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247de06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Restidual(nn.Module):\n",
    "    def __init__(self, input_channels, num_channels, use_1x1conv = False, strides = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = nn.Conv2d(in_channels = input_channels, out_channels = num_channels, \n",
    "                               kernel_size = 3, padding = 1, stride = strides)\n",
    "        self.conv2 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, \n",
    "                               kernel_size = 3, padding = 1, stride = 1)\n",
    "        if use_1x1conv == True:\n",
    "            self.conv3 = nn.Conv2d(in_channels = input_channels, out_channels = num_channels, \n",
    "                                   kernel_size = 1, stride = strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3 != None:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        \n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36bfd2",
   "metadata": {},
   "source": [
    "### 2.1 输入数据实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846a6c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Restidual(3, 3)\n",
    "X = torch.rand(4, 3, 6, 6)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319e7d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Restidual(3, 6, use_1x1conv = True, strides = 2)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6136dead",
   "metadata": {},
   "source": [
    "### 2.2 自定义resnet块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777b412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_restiduals, first_block = True):\n",
    "    blk = []\n",
    "    for i in range(num_restiduals):\n",
    "        if (i == 0) and (first_block == True):\n",
    "            blk.append(Restidual(input_channels, num_channels, use_1x1conv = True, strides = 2))\n",
    "        else:\n",
    "            blk.append(Restidual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9675686",
   "metadata": {},
   "source": [
    "## 3 搭建ResNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9bab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block = False))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0852fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(b1, b2, b3, b4, b5,\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten(), nn.Linear(512, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4e89b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Restidual(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Restidual(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Restidual(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Restidual(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Restidual(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Restidual(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Restidual(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Restidual(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ede4c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 128, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 512])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac60a0",
   "metadata": {},
   "source": [
    "## 4 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce7fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Resize([224, 224])])\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root = \"C:/Users/CCU6/Practice/pytorch/data\", train = True,\n",
    "                                                transform = trans, download = True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root = \"C:/Users/CCU6/Practice/pytorch/data\", train = False,\n",
    "                                                transform = trans, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b485daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: C:/Users/CCU6/Practice/pytorch/data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Resize(size=[224, 224], interpolation=bilinear, max_size=None, antialias=None)\n",
       "            ),\n",
       " 60000,\n",
       " torch.Size([1, 224, 224]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train, mnist_train.__len__(), mnist_train[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56aa045",
   "metadata": {},
   "source": [
    "### 4.1 绘制动图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(num, i, train_loss_his, val_loss_his, train_his_acc, val_his_acc):\n",
    "    plt.figure(num = num)\n",
    "    plt.ion()\n",
    "    plt.cla()\n",
    "    ax1 = plt.subplot2grid((1, 2), (0, 0), colspan=1, rowspan=1)\n",
    "    ax1.grid(ls='-.')\n",
    "    ax1.set_xlim((0, num_epochs))\n",
    "    #ax1.set_ylim(0, 1.6)\n",
    "    ax1.plot(range(i + 1), train_loss_his, label='train_loss')\n",
    "    ax1.plot(range(i + 1), val_loss_his, label='val_loss')\n",
    "    ax1.legend()\n",
    "    ax2 = plt.subplot2grid((1, 2), (0, 1), colspan=1, rowspan=1)\n",
    "    ax2.grid(ls='-.')\n",
    "    ax2.set_xlim(0, num_epochs)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.plot(range(i + 1), train_his_acc, label='train_accuracy')\n",
    "    ax2.plot(range(i + 1), val_his_acc, label='val_accuracy')\n",
    "    ax2.legend()\n",
    "    display.clear_output(wait=True)\n",
    "    plt.pause(0.0000001)\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef309afa",
   "metadata": {},
   "source": [
    "### 4.2 将网络参数用xavier初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc567dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ee3d4",
   "metadata": {},
   "source": [
    "### 4.3 训练函数\n",
    "- 这里面使用了小批量梯度下降，如果不用批量梯度下降的话（其他参数不变），网络就会不收敛，准确率一直在0.1附近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81dae03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, num_epochs, alpha, device, batch_size):\n",
    "    #定义的东西\n",
    "    train_loss_his = []\n",
    "    val_loss_his = []\n",
    "    train_his_acc = []\n",
    "    val_his_acc = []\n",
    "    train_data_batch = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "    val_data_batch = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "    #正式代码\n",
    "    net.apply(init_weight)\n",
    "    print(f\"train on:{device}\")\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = alpha)\n",
    "    loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    for i in range(num_epochs):\n",
    "        train_loss = 0.\n",
    "        train_acc = 0.\n",
    "        net.train()\n",
    "        #每次迭代用batch_size大小的数据集进行训练，一轮共every_num_epoch此迭代。\n",
    "        for k, (data_train, label_train) in enumerate(train_data_batch):\n",
    "            data_train_k = data_train.to(device)\n",
    "            label_train_k = label_train.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_trian_hat = net(data_train_k)\n",
    "            l_train = loss(y_trian_hat, label_train_k)\n",
    "            l_train.mean().backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                train_max_hat = torch.argmax(y_trian_hat, dim = 1)\n",
    "                train_acc_k = sum(train_max_hat == label_train_k)\n",
    "                train_acc += train_acc_k\n",
    "                train_loss += l_train.sum()\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.\n",
    "            val_acc = 0.\n",
    "            #验证集的预测\n",
    "            for data_val, label_val in val_data_batch:\n",
    "                data_val_k = data_val.to(device)\n",
    "                label_val_k = label_val.to(device)\n",
    "                y_val_hat = net(data_val_k)\n",
    "                val_max_hat = torch.argmax(y_val_hat, dim = 1)\n",
    "                val_acc_k = sum(val_max_hat == label_val_k)\n",
    "                l_val = loss(y_val_hat, label_val_k)\n",
    "                val_acc += val_acc_k\n",
    "                val_loss += l_val.sum()\n",
    "            \n",
    "            train_loss_his.append(((train_loss * 1.0)/len(mnist_train)).cpu())\n",
    "            val_loss_his.append(((val_loss * 1.0)/len(mnist_test)).cpu())\n",
    "            train_his_acc.append(((train_acc * 1.0)/len(mnist_train)).cpu())\n",
    "            val_his_acc.append(((val_acc * 1.0)/len(mnist_test)).cpu())\n",
    "        #画出每次迭代的图\n",
    "        plot_image(2, i, train_loss_his, val_loss_his, train_his_acc, val_his_acc)\n",
    "    print(f\"train acc:{max(train_his_acc)}, test acc:{max(val_his_acc)}\")\n",
    "    \n",
    "    return train_loss_his, val_loss_his, train_his_acc, val_his_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc9faa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "num_epochs, alpha, batch_size = 10, 0.05, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c725ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on:cuda:0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loss_his, test_loss_his, train_his_acc, test_his_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(net, num_epochs, alpha, device, batch_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#每次迭代用batch_size大小的数据集进行训练，一轮共every_num_epoch此迭代。\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, (data_train, label_train) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_data_batch):\n\u001b[1;32m---> 21\u001b[0m     data_train_k \u001b[38;5;241m=\u001b[39m \u001b[43mdata_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     label_train_k \u001b[38;5;241m=\u001b[39m label_train\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_his, test_loss_his, train_his_acc, test_his_acc = train_model(net, num_epochs, alpha, device, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24511b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0660bead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
