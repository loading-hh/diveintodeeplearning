{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c62ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4413f",
   "metadata": {},
   "source": [
    "## 1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2048a2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Type    object\n",
       " City    object\n",
       " dtype: object,\n",
       " Type    object\n",
       " City    object\n",
       " dtype: object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "train_data.dtypes[train_data.dtypes == 'object'], test_data.dtypes[test_data.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66be50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47434, 21), (31623, 20))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "788dee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Sold Price          Type  Build year  Full bathrooms  Last Sold Price  \\\n",
      "0   0     3825000  SingleFamily        55.0             NaN              NaN   \n",
      "1   1      505000  SingleFamily        98.0             2.0         328000.0   \n",
      "2   2      140000  SingleFamily        66.0             1.0              NaN   \n",
      "3   3     1775000  SingleFamily        77.0             3.0        1500000.0   \n",
      "\n",
      "          City  \n",
      "0    Los Altos  \n",
      "1  Los Angeles  \n",
      "2   Strawberry  \n",
      "3  Culver City  \n",
      "      Id          Type  Build year      Lot  Total interior livable area  \\\n",
      "0  47439  SingleFamily         4.0    940.0                       1677.0   \n",
      "1  47440  SingleFamily       100.0  10018.8                       1729.0   \n",
      "2  47441  SingleFamily         4.0    940.0                       1677.0   \n",
      "3  47442  SingleFamily         4.0    940.0                       1609.0   \n",
      "\n",
      "   Last Sold Price         City  \n",
      "0         819000.0   Dodgertown  \n",
      "1          15000.0  San Leandro  \n",
      "2              NaN  Los Angeles  \n",
      "3         810000.0   Dodgertown  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0:4, [0, 1, 2, 3, 6, -2, -1]])\n",
    "print(test_data.iloc[0:4, [0, 1, 2, 3, 6, -2, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bc67c8",
   "metadata": {},
   "source": [
    "## 2 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ffe41",
   "metadata": {},
   "source": [
    "#### 将id去掉，并且将train的sold price放入train_y中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801ab177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Type  Build year     Lot  Last Sold Price         City\n",
      "0  SingleFamily        55.0     1.0              NaN    Los Altos\n",
      "1  SingleFamily        98.0   447.0         328000.0  Los Angeles\n",
      "2  SingleFamily        66.0  9147.0              NaN   Strawberry\n",
      "3  SingleFamily        77.0     NaN        1500000.0  Culver City\n",
      "4    VacantLand         NaN     NaN         900000.0      Creston\n",
      "5  SingleFamily       119.0  3576.0         200000.0     Stockton\n",
      "0    3825000\n",
      "1     505000\n",
      "2     140000\n",
      "3    1775000\n",
      "Name: Sold Price, dtype: int64\n",
      "            Type  Build year       Lot  Last Sold Price           City\n",
      "0   SingleFamily         4.0     940.0         819000.0     Dodgertown\n",
      "1   SingleFamily       100.0   10018.8          15000.0    San Leandro\n",
      "2   SingleFamily         4.0     940.0              NaN    Los Angeles\n",
      "3   SingleFamily         4.0     940.0         810000.0     Dodgertown\n",
      "4   SingleFamily         7.0    2613.6        1041000.0        Hayward\n",
      "5   SingleFamily        62.0    6000.0         511000.0   Garden Grove\n",
      "6   SingleFamily        51.0   20464.0              NaN        Topanga\n",
      "7   SingleFamily        38.0  100188.0              NaN       Tuolumne\n",
      "8   SingleFamily        95.0    6026.0        1125000.0    Los Angeles\n",
      "9   SingleFamily        36.0    6969.0         359500.0       Woodland\n",
      "10  SingleFamily        65.0    6456.0              NaN       Glendora\n",
      "11         Condo        16.0       NaN              NaN  San Francisco\n",
      "12    VacantLand         NaN       NaN              NaN       Westport\n",
      "13  SingleFamily        30.0   14810.4              NaN    Sierra City\n",
      "14         Condo        18.0       NaN         512000.0     Dodgertown\n",
      "15  SingleFamily        69.0    7873.0         117000.0         Pomona\n",
      "16  SingleFamily        62.0   11761.2         150000.0  Pollock Pines\n",
      "17  SingleFamily       100.0    5389.0              NaN    Los Angeles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((47434, 19), (31623, 19))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_with_nan = train_data.iloc[:, 2:]\n",
    "train_y = train_data.iloc[:, 1]\n",
    "test_x_with_nan = test_data.iloc[:, 1:]\n",
    "print(train_x_with_nan.iloc[0:6, [0, 1, 2, -2, -1]])\n",
    "print(train_y.iloc[0:4])\n",
    "print(test_x_with_nan.iloc[0:18, [0, 1, 2, -2, -1]])\n",
    "train_x_with_nan.shape, test_x_with_nan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b2cd7",
   "metadata": {},
   "source": [
    "#### 使用每个特征的平均值来填充nan(not a number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb83e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_x_with_nan.dtypes[train_x_with_nan.dtypes != 'object'].index\n",
    "b = test_x_with_nan.dtypes[test_x_with_nan.dtypes != 'object'].index\n",
    "train_x_mean = train_x_with_nan[a].mean()\n",
    "test_x_mean = test_x_with_nan[b].mean()\n",
    "train_x_fill = train_x_with_nan[a].fillna(train_x_mean)\n",
    "test_x_fill = test_x_with_nan[b].fillna(test_x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032eb9b",
   "metadata": {},
   "source": [
    "#### 使用z-score标准化将数据范围重新划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529b462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47434, 19),\n",
       " (31623, 19),\n",
       "            Type  Build year       Lot  Last Sold Price         City\n",
       " 0  SingleFamily   -0.056214 -0.078544         0.000000    Los Altos\n",
       " 1  SingleFamily    0.825179 -0.077088        -0.515180  Los Angeles\n",
       " 2  SingleFamily    0.169259 -0.048694         0.000000   Strawberry\n",
       " 3  SingleFamily    0.394731  0.000000         0.742862  Culver City\n",
       " 4    VacantLand    0.000000  0.000000         0.098813      Creston\n",
       " 5  SingleFamily    1.255626 -0.066876        -0.652577     Stockton,\n",
       "            Type  Build year       Lot  Last Sold Price          City\n",
       " 0  SingleFamily   -0.321192 -0.023875         0.559376    Dodgertown\n",
       " 1  SingleFamily    0.385274 -0.023490        -0.999101   San Leandro\n",
       " 2  SingleFamily   -0.321192 -0.023875         0.000000   Los Angeles\n",
       " 3  SingleFamily   -0.321192 -0.023875         0.541930    Dodgertown\n",
       " 4  SingleFamily   -0.299115 -0.023804         0.989701       Hayward\n",
       " 5  SingleFamily    0.105631 -0.023660        -0.037652  Garden Grove)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_std = train_x_fill[a].std()\n",
    "test_x_std = test_x_fill[b].std()\n",
    "train_x_z_score = (train_x_fill - train_x_mean) / train_x_std\n",
    "test_x_z_score = (test_x_fill - test_x_mean) / test_x_std\n",
    "train_x_conbin = pd.concat([train_x_with_nan.iloc[:, [0]], train_x_z_score, train_x_with_nan.iloc[:, [-1]]], axis = 1)\n",
    "test_x_conbin = pd.concat([test_x_with_nan.iloc[:, [0]], test_x_z_score, test_x_with_nan.iloc[:, [-1]]], axis = 1)\n",
    "train_x_conbin.shape, test_x_conbin.shape, train_x_conbin.iloc[0:6, [0, 1, 2, -2, -1]], test_x_conbin.iloc[0:6, [0, 1, 2, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d4192",
   "metadata": {},
   "source": [
    "#### 将训练集与测试集合到一块，因为训练集与测试集one-hot后的特征数量不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceaf3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature = pd.concat([train_x_conbin, test_x_conbin])\n",
    "all_feature_one_hot = pd.get_dummies(all_feature, dummy_na=True)\n",
    "all_feature_one_hot = all_feature_one_hot.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ca3f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79057, 1349), 47434)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feature_one_hot.shape, train_x_conbin.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c63c2",
   "metadata": {},
   "source": [
    "#### 因为type和city的特征数量不一样，所以将这两个特征去掉。只用剩下来的17个特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549e85ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47434, 1124), (31623, 1031))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_one_hot = pd.get_dummies(train_x_conbin, dummy_na=True)\n",
    "test_x_one_hot = pd.get_dummies(test_x_conbin, dummy_na=True)\n",
    "train_x_one_hot.shape, test_x_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194e829",
   "metadata": {},
   "source": [
    "#### 将数据变为tensor格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20739d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0562, -0.0785,  0.0000,  ...,  0.1570,  1.0957,  0.0000],\n",
       "         [ 0.8252, -0.0771, -0.0051,  ..., -0.2338, -0.3019, -0.5152],\n",
       "         [ 0.1693, -0.0487, -0.0049,  ..., -0.5911, -0.4331,  0.0000],\n",
       "         ...,\n",
       "         [ 0.9687, -0.0565, -0.0051,  ..., -0.1746,  0.3716,  1.4406],\n",
       "         [-1.0401, -0.0591, -0.0049,  ..., -0.1489, -0.3114, -0.3306],\n",
       "         [ 0.3742, -0.0759, -0.0053,  ..., -0.5527, -0.2170,  0.0000]]),\n",
       " tensor([[-0.3212, -0.0239, -0.0050,  ...,  0.0000, -0.0637,  0.5594],\n",
       "         [ 0.3853, -0.0235, -0.0068,  ...,  0.0549, -0.3408, -0.9991],\n",
       "         [-0.3212, -0.0239, -0.0050,  ...,  0.0000, -0.0291,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.3728,  0.0000],\n",
       "         [-0.0563,  0.0000, -0.0059,  ..., -0.2204, -0.3711, -0.1171],\n",
       "         [-0.1225,  0.0000, -0.0068,  ...,  0.0380, -0.2724,  0.0040]]),\n",
       " torch.Size([47434, 17]),\n",
       " torch.Size([47434, 1]),\n",
       " torch.Size([31623, 17]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_1 = torch.tensor(train_x_z_score.values, dtype = torch.float32)\n",
    "train_y_1 = torch.tensor(train_y, dtype = torch.float32)\n",
    "train_y_1 = train_y_1.reshape(-1, 1)\n",
    "test_x_1 = torch.tensor(test_x_z_score.values, dtype = torch.float32)\n",
    "train_x_1, test_x_1, train_x_1.shape, train_y_1.shape, test_x_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed22fbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0562, -0.0785,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8252, -0.0771, -0.0051,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1693, -0.0487, -0.0049,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.9687, -0.0565, -0.0051,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.0401, -0.0591, -0.0049,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3742, -0.0759, -0.0053,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[-0.3212, -0.0239, -0.0050,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3853, -0.0235, -0.0068,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.3212, -0.0239, -0.0050,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0563,  0.0000, -0.0059,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.1225,  0.0000, -0.0068,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " torch.Size([47434, 1349]),\n",
       " torch.Size([47434, 1]),\n",
       " torch.Size([31623, 1349]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n  = train_x_conbin.shape[0]\n",
    "train_x_2 = torch.tensor(all_feature_one_hot[:n].values, dtype = torch.float32)\n",
    "train_y_2 = torch.tensor(train_y, dtype = torch.float32)\n",
    "train_y_2 = train_y_2.reshape(-1, 1)\n",
    "test_x_2 = torch.tensor(all_feature_one_hot[n:].values, dtype = torch.float32)\n",
    "train_x_2, test_x_2, train_x_2.shape, train_y_2.shape, test_x_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5edd62",
   "metadata": {},
   "source": [
    "## 3 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344438c3",
   "metadata": {},
   "source": [
    "### 对数据分为k份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61aab4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    k:共分几折\n",
    "    i:第i折\n",
    "    X:为输入样本\n",
    "    y:为输入标签\n",
    "'''\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7c939",
   "metadata": {},
   "source": [
    "### 3.1 使用线性回归，即单个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0085d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss(reduction='mean')\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(train_x_1.shape[1], 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32, 16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(16, 1),\n",
    "                        nn.ReLU())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3975d",
   "metadata": {},
   "source": [
    "#### 对成本进行相对误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7210746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(net, features, labels):\n",
    "    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
    "    clipped_preds = torch.clamp(net(features), min = 1)\n",
    "    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac5097",
   "metadata": {},
   "source": [
    "#### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd6cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, valid_features, valid_labels,\n",
    "          num_epochs, learning_rate, weight_decay):\n",
    "    train_loss_his, valid_loss_his = [], []\n",
    "    # 这里使用的是Adam优化算法\n",
    "    optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                 lr = learning_rate,\n",
    "                                 weight_decay = weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        l = loss(net(train_features), train_labels)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_his.append(log_rmse(net, train_features, train_labels))\n",
    "        if valid_labels is not None:\n",
    "            valid_loss_his.append(log_rmse(net, valid_features, valid_labels))\n",
    "    #print(1, torch.clamp(net(train_features), min = 1))\n",
    "    #print(2, torch.log(torch.clamp(net(train_features), min = 1)))\n",
    "    #print(3, torch.log(train_labels))\n",
    "    #a = torch.log(torch.clamp(net(train_features), min = 1)) - torch.log(train_labels)\n",
    "    #print(sum(a), sum(a) / len(train_labels), torch.sqrt(sum(a) / len(train_labels)))\n",
    "    #print(4, loss(torch.log(torch.clamp(net(train_features), min = 1)), torch.log(train_labels)))\n",
    "    return train_loss_his, valid_loss_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d6b3d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折1，训练log rmse:inf, 验证log rmse:0.489675\n",
      "折2，训练log rmse:inf, 验证log rmse:0.496444\n",
      "折3，训练log rmse:inf, 验证log rmse:0.490551\n",
      "折4，训练log rmse:inf, 验证log rmse:0.349677\n",
      "折5，训练log rmse:0.476244, 验证log rmse:inf\n",
      "5-折验证: 平均训练log rmse: inf, 平均验证log rmse: inf\n"
     ]
    }
   ],
   "source": [
    "k, num_epochs, learning_rate, weight_decay = 5, 100, 0.8, 0.9\n",
    "train_loss_sum, valid_loss_sum = 0., 0.\n",
    "for i in range(k):\n",
    "    X_train, y_train, X_valid, y_valid = get_k_fold_data(k, i, train_x_1, train_y_1)\n",
    "    net = get_net()\n",
    "    train_loss, valid_loss = train(net, X_train, y_train, X_valid, y_valid, num_epochs, learning_rate, weight_decay)\n",
    "    \n",
    "    train_loss_sum = train_loss[-1] + train_loss_sum\n",
    "    valid_loss_sum = valid_loss[-1] + valid_loss_sum\n",
    "    \n",
    "    print(f'折{i + 1}，训练log rmse:{float(train_loss[-1]):f}, '\n",
    "              f'验证log rmse:{float(valid_loss[-1]):f}')\n",
    "print(f'{k}-折验证: 平均训练log rmse: {float(train_loss_sum / k):f}, '\n",
    "      f'平均验证log rmse: {float(valid_loss_sum / k):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed71891",
   "metadata": {},
   "source": [
    "## 4 找到合适的超参数后将所有的训练集训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ada862ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_net()\n",
    "train_loss = train(net, train_x_1, train_y_1, None, None, num_epochs * 5, learning_rate, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63b23aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id            int64\n",
       "Sold Price    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = net(test_x_1).detach().numpy()\n",
    "sub_txt = pd.read_csv(\"data/sample_submission.csv\")\n",
    "sub_txt.dtypes[sub_txt.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "addf0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_txt[\"Sold Price\"] = pd.Series(preds.reshape(1, -1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c24543f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_txt.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
