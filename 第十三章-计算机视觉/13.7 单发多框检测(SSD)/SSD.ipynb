{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af97617b",
   "metadata": {},
   "source": [
    "# SSD\n",
    "- 运用ssd算法的思想构建一个自己的ssd目标检测模型,自己构建的算法流程图如下所示.\n",
    "<img src=\"流程图.png\" width=\"1000\" height=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ed82a",
   "metadata": {},
   "source": [
    "## 1 加载相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89343449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from IPython import display\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc13f45",
   "metadata": {},
   "source": [
    "## 加载相关函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d6ee60",
   "metadata": {},
   "source": [
    "### 画图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c445c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(num, i, train_loss_his, val_loss_his, train_his_acc, val_his_acc):\n",
    "    plt.figure(num = num)\n",
    "    plt.ion()\n",
    "    plt.cla()\n",
    "    ax1 = plt.subplot2grid((1, 2), (0, 0), colspan=1, rowspan=1)\n",
    "    ax1.set_xlim((0, num_epochs))\n",
    "    #ax1.set_ylim(0, 1.6)\n",
    "    ax1.plot(range(i + 1), train_loss_his, label='train_loss')\n",
    "    ax1.plot(range(i + 1), val_loss_his, label='val_loss')\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "    ax2 = plt.subplot2grid((1, 2), (0, 1), colspan=1, rowspan=1)\n",
    "    ax2.set_xlim(0, num_epochs)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.plot(range(i + 1), train_his_acc, label='train_accuracy')\n",
    "    ax2.plot(range(i + 1), val_his_acc, label='val_accuracy')\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "    display.clear_output(wait=True)\n",
    "    plt.pause(0.0000001)\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a73db",
   "metadata": {},
   "source": [
    "### 由特征图的大小在原图生成default boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b7f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multibox_prior(feature_data, scale, ratio, origin_w = 256, origin_h = 256):\n",
    "    \"\"\"\n",
    "    竖直方向为x,横着方向为y.\n",
    "    feature_data为输入的数据,每个位置生成锚框,通道数没有用到,批量也没有用到,因为同一批量输入进来的数据的尺寸和通道数都是一样的,\n",
    "    而此函数是将特征映射图的每个位置映射到原图(锚框中心点不一定是整数),然后按scale和ratio的值生成锚框.所以输入数据在这个计算中\n",
    "    的锚框只计算一次即可.\n",
    "    input:\n",
    "        feature_data:输入的特征映射图\n",
    "        scale:是缩放比，是得出的锚框面积占原图像的多少\n",
    "        ratio:宽高比，生成的锚框的宽高比\n",
    "        origin_w:原图像的宽\n",
    "        origin_h:原图像的高\n",
    "    output:\n",
    "        返回锚框，（批量大小，锚框数量，每个锚框坐标（四个值））,是左上角坐标(x,y)和右下角坐标(x,y).\n",
    "        同一个位置的锚框是挨着的.每一行代表一个锚框.位置是从左到右,从上到下.是z型的.\n",
    "        锚框的坐标值都进行了归一化.\n",
    "    \"\"\"\n",
    "    ##输入特征图的高宽\n",
    "    in_height, in_width = feature_data.shape[-2], feature_data.shape[-1]\n",
    "    device, num_scale, num_ratio = feature_data.device, len(scale), len(ratio)\n",
    "    boxes_per_pixel = (num_scale + num_ratio - 1)\n",
    "    scale_tensor = torch.tensor(scale, device = device)\n",
    "    ratio_tensor = torch.tensor(ratio, device = device)\n",
    "    \n",
    "    #生成所有锚框中心点,因为将原图的长宽都归一化了,所以步长要为1/特征图的高或宽(因为这里的特征图的高宽一样)\n",
    "    ##先生成特征图的每个像素的中心(加0.5就是为了中心),然后再除以特征图的高宽,将中心点归一化.\n",
    "    center_x_all = (torch.arange(in_height, device = device) + 0.5) / in_height\n",
    "    center_y_all = (torch.arange(in_width, device = device) + 0.5) / in_width\n",
    "    center_x, center_y = torch.meshgrid(center_x_all, center_y_all, indexing = 'ij')\n",
    "    center_x, center_y = center_x.reshape(-1), center_y.reshape(-1)  #转为一维向量，对应xy构成中心点坐标。\n",
    "    \n",
    "    ##生成每个锚框的宽和高，是由缩放比和宽高比计算得到的。\n",
    "    ##w和h是先scale乘ratio第一个元素，再计算scale第一个元素乘ratio除了第一个元素的其他元素。用torch.cat来合到一维上。这个是无所谓的,\n",
    "    ##在这里是因为生成少一点的default boxes.\n",
    "    w = torch.cat((torch.sqrt(scale_tensor * ratio_tensor[0]), torch.sqrt(scale_tensor[0] * ratio_tensor[1:])))\n",
    "    h = torch.cat((torch.sqrt(scale_tensor / ratio_tensor[0]), torch.sqrt(scale_tensor[0] / ratio_tensor[1:])))\n",
    "    \n",
    "    ##宽高除以2来得到宽高的一半，以便通过中心点快速找到每个锚框右上角和右下加.\n",
    "    ##每个像素有boxes_per_pixel边框，故重复in_height * in_width像素次数。\n",
    "    anchor_manipulations = torch.stack((-w, -h, w, h), dim = 1).repeat(in_height * in_width, 1) / 2\n",
    "    \n",
    "    ##每个中心点有boxes_per_pixel锚框\n",
    "    ##有in_height * in_width个像素，每个像素有boxes_per_pixel边框。\n",
    "    out_grid = torch.stack((center_x, center_y, center_x, center_y), dim = 1).repeat_interleave(boxes_per_pixel, dim=0)\n",
    "    ##得到每个像素的boxes_per_pixel个锚框\n",
    "    output = (out_grid + anchor_manipulations).unsqueeze(0)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "badb0710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 45, 4]),\n",
       " tensor([[[-0.2663, -0.2663,  0.5997,  0.5997],\n",
       "          [-0.1869, -0.1869,  0.5202,  0.5202],\n",
       "          [-0.0833, -0.0833,  0.4167,  0.4167],\n",
       "          [-0.4457, -0.1395,  0.7790,  0.4729],\n",
       "          [-0.1395, -0.4457,  0.4729,  0.7790],\n",
       "          [-0.2663,  0.0670,  0.5997,  0.9330],\n",
       "          [-0.1869,  0.1464,  0.5202,  0.8536],\n",
       "          [-0.0833,  0.2500,  0.4167,  0.7500],\n",
       "          [-0.4457,  0.1938,  0.7790,  0.8062],\n",
       "          [-0.1395, -0.1124,  0.4729,  1.1124],\n",
       "          [-0.2663,  0.4003,  0.5997,  1.2663],\n",
       "          [-0.1869,  0.4798,  0.5202,  1.1869],\n",
       "          [-0.0833,  0.5833,  0.4167,  1.0833],\n",
       "          [-0.4457,  0.5271,  0.7790,  1.1395],\n",
       "          [-0.1395,  0.2210,  0.4729,  1.4457],\n",
       "          [ 0.0670, -0.2663,  0.9330,  0.5997],\n",
       "          [ 0.1464, -0.1869,  0.8536,  0.5202],\n",
       "          [ 0.2500, -0.0833,  0.7500,  0.4167],\n",
       "          [-0.1124, -0.1395,  1.1124,  0.4729],\n",
       "          [ 0.1938, -0.4457,  0.8062,  0.7790],\n",
       "          [ 0.0670,  0.0670,  0.9330,  0.9330],\n",
       "          [ 0.1464,  0.1464,  0.8536,  0.8536],\n",
       "          [ 0.2500,  0.2500,  0.7500,  0.7500],\n",
       "          [-0.1124,  0.1938,  1.1124,  0.8062],\n",
       "          [ 0.1938, -0.1124,  0.8062,  1.1124],\n",
       "          [ 0.0670,  0.4003,  0.9330,  1.2663],\n",
       "          [ 0.1464,  0.4798,  0.8536,  1.1869],\n",
       "          [ 0.2500,  0.5833,  0.7500,  1.0833],\n",
       "          [-0.1124,  0.5271,  1.1124,  1.1395],\n",
       "          [ 0.1938,  0.2210,  0.8062,  1.4457],\n",
       "          [ 0.4003, -0.2663,  1.2663,  0.5997],\n",
       "          [ 0.4798, -0.1869,  1.1869,  0.5202],\n",
       "          [ 0.5833, -0.0833,  1.0833,  0.4167],\n",
       "          [ 0.2210, -0.1395,  1.4457,  0.4729],\n",
       "          [ 0.5271, -0.4457,  1.1395,  0.7790],\n",
       "          [ 0.4003,  0.0670,  1.2663,  0.9330],\n",
       "          [ 0.4798,  0.1464,  1.1869,  0.8536],\n",
       "          [ 0.5833,  0.2500,  1.0833,  0.7500],\n",
       "          [ 0.2210,  0.1938,  1.4457,  0.8062],\n",
       "          [ 0.5271, -0.1124,  1.1395,  1.1124],\n",
       "          [ 0.4003,  0.4003,  1.2663,  1.2663],\n",
       "          [ 0.4798,  0.4798,  1.1869,  1.1869],\n",
       "          [ 0.5833,  0.5833,  1.0833,  1.0833],\n",
       "          [ 0.2210,  0.5271,  1.4457,  1.1395],\n",
       "          [ 0.5271,  0.2210,  1.1395,  1.4457]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1, 3 ,3, 3))\n",
    "y = multibox_prior(x, scale = [0.75, 0.5, 0.25], ratio = [1, 2, 0.5])\n",
    "y.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52b3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        boxes1:输入的第一组锚框(n, 4)n是有多少个锚框,4是锚框的左上角和左下角的四个值先x后y.\n",
    "        boxes2:输入的第二组锚框(n, 4)n是有多少个锚框,4是锚框的左上角和左下角的四个值先x后y.\n",
    "    output:\n",
    "        返回n个锚框的交并比.输出的每一行是boxes1的每一个锚框与boxes2的每个锚框的交并比.\n",
    "    \"\"\"\n",
    "    def box_area(boxes):\n",
    "        area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "        return area\n",
    "    area1 = box_area(boxes1)\n",
    "    area2 = box_area(boxes2)\n",
    "    \n",
    "    #注意:是boxes1与boxes2中的每个锚框都要计算交并比,并不是只计算对应行的锚框的交并比.这个要进行注意\n",
    "    #找输入锚框boxes1和boxes2的左上角的最大的坐标,计算交并比.用了广播机制.\n",
    "    inter_upperleft = torch.max(boxes1[:, :2].unsqueeze(dim = 1), boxes2[:, :2])\n",
    "    #找输入锚框boxes1和boxes2的右下角的最小坐标.用了广播机制.\n",
    "    inter_lowerright = torch.min(boxes1[:, 2:].unsqueeze(dim = 1), boxes2[:, 2:])\n",
    "    #clamp(min = 0)是因为有些锚框是没有相交的,这样算的值都是负的.\n",
    "    inter = (inter_lowerright - inter_upperleft).clamp(min = 0)\n",
    "    \n",
    "    #相交区域\n",
    "    inter_area = inter[:, :, 0] * inter[:, :, 1]\n",
    "    #相并区域,union_area行是boxes1的锚框,列是boxes1中每个锚框与boxes2中每个锚框相并区域,用了广播机制.\n",
    "    union_area = area1.unsqueeze(dim = 1) + area2 - inter_area\n",
    "    \n",
    "    return inter_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4844eb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3333, 0.5469, 0.5469],\n",
       "         [0.5000, 0.5300, 0.5300],\n",
       "         [1.0000, 0.3333, 0.3333]]),\n",
       " tensor([[-0.2663, -0.2663,  0.5997,  0.5997],\n",
       "         [-0.1869, -0.1869,  0.5202,  0.5202],\n",
       "         [-0.0833, -0.0833,  0.4167,  0.4167]]),\n",
       " tensor([[-0.0833, -0.0833,  0.4167,  0.4167],\n",
       "         [-0.4457, -0.1395,  0.7790,  0.4729],\n",
       "         [-0.1395, -0.4457,  0.4729,  0.7790]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2 = y[0, 0:3], y[0, 2:5]\n",
    "box_iou(x1, x2), x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4ae580",
   "metadata": {},
   "outputs": [],
   "source": [
    "##(正样本个数,4)4是左上角与右下角坐标, (负样本个数,4)4是左上角与右下角坐标, (正样本个数, 4)4是预测的偏移量.\n",
    "def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold = 0.5):\n",
    "    \"\"\"\n",
    "    将最接近的真实边界框分配给锚框,构建的iou矩阵,每行是每个anchor与每个真实框的iou.先通过阈值分配,再找最值分配(这个更重要),这样可以加快速度.\n",
    "    input:\n",
    "        ground_truth:二维张量,真实边界框,是自己标注的边界框.(真实边界框个数,4)是一张输入图片中有几个真实边界框,4是左上角与右下角坐标.\n",
    "        anchors:二维张量,输入图片在每个特征映射图上生成的所有边界框.是一张图片生成的所以边界框.(锚框个数,4)是一张图片生成的所有边界框,4是左上角与右下角坐标.\n",
    "        device:数据在gpu还是cpu上\n",
    "        iou_threshold:每个真实边界框都有锚框后,为了补充正样本,通过阈值找到与真实边界框iou超过阈值的锚框.\n",
    "    output:\n",
    "        anchors_bbox_map:一维张量,返回锚框分配给真实框的索引.返回一个一维张量(锚框个数,)值为整数是真实框的索引,-1为没有分配给真实框的锚框\n",
    "    \"\"\"\n",
    "    ##得到输入锚框与真实框的个数.\n",
    "    num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0]\n",
    "    ##计算锚框与真实框的iou,每一行是每一个锚框与所有真实框的iou\n",
    "    jaccard = box_iou(anchors, ground_truth)\n",
    "    #print(f\"jaccard:{jaccard}\")\n",
    "    ##对于每个锚框，分配的真实边界框的张量,初始值均分配为-1，表示未分配真实边界框，长度为num_anchors,即锚框数量\n",
    "    ##数据类型是torch.long是因为真实框的个数可能有很多.\n",
    "    anchors_bbox_map = torch.full((num_anchors, ), -1, dtype = torch.long, device = device)\n",
    "    ##找到iou矩阵中每一行的最大值与索引\n",
    "    max_ious, index = torch.max(jaccard, dim = 1)\n",
    "    #print(f\"max_ious:{max_ious} \\n index:{index}\")\n",
    "    ##找到锚框大于阈值的锚框的索引\n",
    "    anc_i = torch.nonzero(max_ious >= iou_threshold).reshape(-1)\n",
    "    ##找到锚框大于阈值时应该分配的真实框索引\n",
    "    box_j = index[max_ious >= iou_threshold]\n",
    "    #print(f\"anc_i:{anc_i} \\n box_j:{box_j}\")\n",
    "    ##先通过阈值分配真实框\n",
    "    anchors_bbox_map[anc_i] = box_j\n",
    "    \n",
    "    ##找最值来分配真实框\n",
    "    col_replace = torch.full((num_anchors,), -1, dtype = torch.long, device = device)\n",
    "    row_replace = torch.full((num_gt_boxes,), -1, dtype = torch.long, device = device)\n",
    "    for _ in range(num_gt_boxes):\n",
    "        index = torch.argmax(jaccard)\n",
    "        anc_ind = (index / num_gt_boxes).long()\n",
    "        GTb_ind = (index % num_gt_boxes).long()\n",
    "        anchors_bbox_map[anc_ind] = GTb_ind\n",
    "        jaccard[anc_ind] = row_replace\n",
    "        jaccard[:, GTb_ind] = col_replace\n",
    "    \n",
    "    return anchors_bbox_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9fe4830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = torch.tensor([[10, 10, 20, 20], [15, 15, 30, 30], [20, 20, 40, 40]], device='cpu')\n",
    "anchors = torch.tensor([[5, 5, 40, 40], [15, 15, 45, 45], [30, 30, 70, 70]], device='cpu')\n",
    "assign_anchor_to_bbox(ground_truth, anchors, torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707fe10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_boxes(anchors, assigned_bb, eps=1e-6):\n",
    "    \"\"\"\n",
    "    对锚框偏移量的转换,anchors与assigned_bb的框的个数都是相同的,第几个anchors就对应分配的真实框在第几个assigned_bb\n",
    "    input:\n",
    "        anchors:锚框.二维张量,(所有的锚框,4)是一张输入图片所有的锚框,\n",
    "                4是左上角与右下角坐标.已分配真实框的锚框.\n",
    "        assigned_bb:二维张量.(锚框个数,4)是一张图片标注的所有真实框,4是左上角与右下角坐标.行值全为0的值对应的行数的锚框没有分配真实边界框\n",
    "        eps:是防止被除数与除数太小导致除法时出现问题.\n",
    "    output:\n",
    "        offset:返回锚框分配给真实框的偏移量.返回一个二维张量(锚框个数, 4)，经过别的函数处理，没有被分配真实框的锚框的四个值才是全为0.\n",
    "    \"\"\"\n",
    "    def box_corner_to_center(boxes):\n",
    "        x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
    "        cx = (x1 + x2) / 2\n",
    "        cy = (y1 + y2) / 2\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        boxes = torch.stack((cx, cy, w, h), dim = -1)\n",
    "        return boxes\n",
    "    c_anc = box_corner_to_center(anchors)\n",
    "    c_assigned_bb = box_corner_to_center(assigned_bb)\n",
    "    offset_xy = (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]\n",
    "    offset_wh = torch.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:])\n",
    "    offset = torch.cat([offset_xy, offset_wh], axis=1)\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "300b42e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000, -0.5108, -0.5108],\n",
       "        [-0.0333, -0.0333, -0.2231, -0.2231]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors = torch.tensor([[10, 10, 20, 20], [15, 15, 30, 30]])\n",
    "assigned_bb = torch.tensor([[12, 12, 18, 18], [16, 16, 28, 28]])\n",
    "offset_boxes(anchors, assigned_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d784c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multibox_target(anchors, labels):\n",
    "    \"\"\"\n",
    "    此函数将背景类别的索引设置为零,然后将新类别的整数索引递增1\n",
    "    input:\n",
    "        anchors:所有锚框的集合，形状为（batch_size, num_gt_boxes, 4），其中最后一维4代表[x1, y1, x2, y2]。\n",
    "        labels:包含真实边界框和类别标签的张量，形状为(batch_size, num_gt_boxes, 5)，其中最后一维5代表[class_label, x1, y1, x2, y2]。\n",
    "    output:\n",
    "        bbox_offset:包含了为每个锚框标记的四个偏移值。 请注意，负类锚框的偏移量被标记为零。是二维数组\n",
    "        bbox_mask:掩码（mask）变量，形状为（批量大小，锚框数的四倍）。掩码变量中的元素与每个锚框的4个偏移量一一对应。\n",
    "                    掩码变量中的零将在计算目标函数之前过滤掉负类偏移量。不是背景则值是1。\n",
    "        class_labels:标记的锚框的类别，0是背景，原类别数加1。\n",
    "    \"\"\"\n",
    "    ##所有输入的图像的anchor都是一样\n",
    "    batch_size, anchors = labels.shape[0], anchors.squeeze(0)\n",
    "    batch_offset, batch_mask, batch_class_labels  = [], [], []\n",
    "    device, num_anchors = anchors.device, anchors.shape[0]\n",
    "    for i in range(batch_size):\n",
    "        label = labels[i, :, :]\n",
    "        anchors_bbox_map = assign_anchor_to_bbox(label[:, 1:], anchors, device)\n",
    "        bbox_mask = (anchors_bbox_map >= 0).float().unsqueeze(1).repeat(1, 4)\n",
    "        ##将类标签和分配的边界框坐标初始化为零，每个值代表每个锚框。\n",
    "        class_label = torch.zeros(num_anchors, dtype = torch.long, device=device)\n",
    "        assigned_bb = torch.zeros((num_anchors, 4), dtype = torch.float32, device=device)\n",
    "        ##使用真实边界框来标记锚框的类别。如果一个锚框没有被分配，标记其为背景（值为零）\n",
    "        ##分配有真实框的锚框的索引\n",
    "        indices_true  = torch.nonzero(anchors_bbox_map >= 0)\n",
    "        ##得到锚框所分配的真实框的索引\n",
    "        bb_idx = anchors_bbox_map[indices_true]\n",
    "        ##将分配有真实框的锚框的类别标注为真实框的类别数加1，0代表背景。\n",
    "        \"\"\"print(label[bb_idx[0]])\n",
    "        print(anchors[0])\"\"\"\n",
    "        class_label[indices_true] = label[bb_idx, 0].long() + 1\n",
    "        assigned_bb[indices_true] = label[bb_idx, 1:].float()\n",
    "        #print(assigned_bb)\n",
    "        ##偏移量转换\n",
    "        offset = offset_boxes(anchors, assigned_bb) * bbox_mask\n",
    "        \n",
    "        ##放到一起\n",
    "        batch_offset.append(offset.reshape(-1))\n",
    "        batch_mask.append(bbox_mask.reshape(-1))\n",
    "        batch_class_labels.append(class_label)\n",
    "        \n",
    "    bbox_offset = torch.stack(batch_offset)\n",
    "    bbox_mask = torch.stack(batch_mask)\n",
    "    class_labels = torch.stack(batch_class_labels)\n",
    "    return (bbox_offset, bbox_mask, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad173a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000e+00,  0.0000e+00,  9.5367e-07,  9.5367e-07,  0.0000e+00,\n",
       "           0.0000e+00,  9.5367e-07,  9.5367e-07, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -5.1082e-01, -5.1082e-01, -3.3333e-02,\n",
       "          -3.3333e-02, -2.2314e-01, -2.2314e-01, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00]]),\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[1, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [2, 3, 0, 0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([\n",
    "    [[1, 15, 15, 30, 30], [0, 10, 10, 20, 20]],  # 第一个批量的类别标签和边界框\n",
    "    [[1, 12, 12, 18, 18], [2, 16, 16, 28, 28]]   # 第二个批量的类别标签和边界框\n",
    "])\n",
    "# 假设我们有9个锚框\n",
    "anchors = torch.tensor([\n",
    "    [10, 10, 20, 20], [15, 15, 30, 30], [20, 20, 40, 40],\n",
    "    [25, 25, 45, 45], [30, 30, 50, 50], [35, 35, 55, 55],\n",
    "    [40, 40, 60, 60], [45, 45, 65, 65], [50, 50, 70, 70]\n",
    "])\n",
    "multibox_target(anchors, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb2d05",
   "metadata": {},
   "source": [
    "## 2 前向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bb418f",
   "metadata": {},
   "source": [
    "### 2.1 基础网络块\n",
    "- 用的预训练好的ResNet的前6层网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41299edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torchvision.models.resnet18(weights = torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "base_net = nn.Sequential(*list(net.children())[:6])\n",
    "base_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd9e6da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output_shape:\t torch.Size([2, 64, 128, 128])\n",
      "BatchNorm2d output_shape:\t torch.Size([2, 64, 128, 128])\n",
      "ReLU output_shape:\t torch.Size([2, 64, 128, 128])\n",
      "MaxPool2d output_shape:\t torch.Size([2, 64, 64, 64])\n",
      "Sequential output_shape:\t torch.Size([2, 64, 64, 64])\n",
      "Sequential output_shape:\t torch.Size([2, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((2, 3, 256, 256))\n",
    "for layer in base_net:\n",
    "    x = layer(x)\n",
    "    print(layer.__class__.__name__, \"output_shape:\\t\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044cc031",
   "metadata": {},
   "source": [
    "### 2.2 多尺度特征块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd61a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowm_sample_block(in_channels, out_channels):\n",
    "    blk = []\n",
    "    for _ in range(2):\n",
    "        blk.append(nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 3, padding = 1))\n",
    "        blk.append(nn.BatchNorm2d(out_channels))\n",
    "        blk.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    blk.append(nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0))\n",
    "    \n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c8af69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output_shape:\t torch.Size([2, 128, 8, 8])\n",
      "BatchNorm2d output_shape:\t torch.Size([2, 128, 8, 8])\n",
      "ReLU output_shape:\t torch.Size([2, 128, 8, 8])\n",
      "Conv2d output_shape:\t torch.Size([2, 128, 8, 8])\n",
      "BatchNorm2d output_shape:\t torch.Size([2, 128, 8, 8])\n",
      "ReLU output_shape:\t torch.Size([2, 128, 8, 8])\n",
      "MaxPool2d output_shape:\t torch.Size([2, 128, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((2, 128, 8, 8))\n",
    "for layer in dowm_sample_block(128, 128):\n",
    "    x = layer(x)\n",
    "    print(layer.__class__.__name__, \"output_shape:\\t\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ae383",
   "metadata": {},
   "source": [
    "### 2.3 完整模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16f4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(i):\n",
    "    if i == 0:\n",
    "        blk = base_net\n",
    "    elif i == 4:\n",
    "        blk = nn.AdaptiveMaxPool2d((1, 1))\n",
    "    else:\n",
    "        blk = dowm_sample_block(128, 128)\n",
    "    \n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74b310",
   "metadata": {},
   "source": [
    "### 2.4 类别预测\n",
    "- SSD是用卷积层进行预测,输出的所有通道的每个位置为预测不同类别的概率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26b7965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_predict(num_input, num_anchors, num_classes):\n",
    "    \"\"\"\n",
    "    输出的东西并没有说在特征映射图中每个位置的通道对应的值是同一个边框类别在一块,还是边框一组在一块.这个并不用在意,\n",
    "    因为这个对应的值是当我们训练的时候训练集中的东西是怎么放的,最后的输出值是怎么放的.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_channels = num_input, out_channels = num_anchors * (num_classes + 1), kernel_size = 3, padding = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeaeb30",
   "metadata": {},
   "source": [
    "### 2.5 边界框预测\n",
    "- 就是预测边界框的偏移量(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8991dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_predict(num_input, num_anchors):\n",
    "    \"\"\"\n",
    "    输出的东西并没有说在特征映射图中每个位置的通道对应的值是同一个边框类别在一块,还是边框一组在一块.这个并不用在意,\n",
    "    因为这个对应的值是当我们训练的时候训练集中的东西是怎么放的,最后的输出值是怎么放的.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_channels = num_input, out_channels = num_anchors * 4, kernel_size = 3, padding = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55afe682",
   "metadata": {},
   "source": [
    "- 为了将数据展平融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d33f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_preds1(preds):\n",
    "    \"\"\"\n",
    "    为了融合数据变为同一个位置的锚框的预测值挨着，相邻位置也挨着，在特征映射图上行与行是z字形连接。\n",
    "    \"\"\"\n",
    "    loca_preds = []\n",
    "    for i in range(len(preds)):\n",
    "        loca_preds.append(torch.flatten(preds[i].permute(0, 2, 3, 1), start_dim=1))\n",
    "    preds = torch.cat(loca_preds, dim = 1)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5942b0",
   "metadata": {},
   "source": [
    "### 2.6 前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbf84c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_forward(X, blk, scale, ratio, cls_predict, bbox_predict):\n",
    "    \"\"\"\n",
    "    输出的是每个块的输出特征映射图,特征映射图对应的锚框,基于特征映射图的类别预测,基于特征映射图的边界框偏移量的预测.\n",
    "    \"\"\"\n",
    "    Y = blk(X)\n",
    "    anchors = multibox_prior(Y, scale, ratio)\n",
    "    cls_preds = cls_predict(Y)\n",
    "    bbox_preds = bbox_predict(Y)\n",
    "    \n",
    "    return Y, anchors, cls_preds, bbox_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55ddd9",
   "metadata": {},
   "source": [
    "### 2.7 SSD模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38a98a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79], [0.88, 0.961]]\n",
    "ratios = [[1, 2, 0.5]] * 5\n",
    "num_anchors = len(scales[0]) + len(ratios[0]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa9f2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinySSD(nn.Module):\n",
    "    def __init__(self, num_anchors, num_classes, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors = num_anchors\n",
    "        idx_input_channels = [128, 128, 128, 128, 128]\n",
    "        self.blk_ = get_block(0)\n",
    "        self.cls_ = cls_predict(idx_input_channels[0], self.num_anchors, self.num_classes)\n",
    "        self.bbox_ = bbox_predict(idx_input_channels[0], self.num_anchors)\n",
    "        \"\"\"for i in range(5): ##是因为整个SSD网络有五部分\n",
    "            setattr(self, f\"blk_{i}\", get_block(i))\n",
    "            setattr(self, f\"cls_{i}\", cls_predict(idx_input_channels[i], self.num_anchors, self.num_classes))\n",
    "            setattr(self, f\"bbox_{i}\", bbox_predict(idx_input_channels[i], self.num_anchors))\"\"\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.batch_size = len(X)\n",
    "        anchors, cls_preds, bbox_preds = [],  [],  []\n",
    "        \"\"\"for i in range(5):\n",
    "            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(X, getattr(self, f\"blk_{i}\"), scales[i], ratios[i], \n",
    "                                                                     getattr(self, f\"cls_{i}\"), getattr(self, f\"bbox_{i}\"))\n",
    "        anchors = torch.cat(anchors, dim=1)\n",
    "        cls_preds = concat_preds(cls_preds)\n",
    "        ##不用在意形状改变后类别是同一个锚框的预测类别挨着还是同一个类别预测值挨着,\n",
    "        ##这是因为具体哪种情况是由训练的时候我的训练集的东西是怎么放的.\n",
    "        cls_preds = cls_preds.reshape(cls_preds.shape[0], -1, self.num_classes + 1)\n",
    "        bbox_preds = concat_preds(bbox_preds)\"\"\"\n",
    "        Y, anchor, cls_pred, bbox_pred = blk_forward(X, self.blk_, scales[0], ratios[0], self.cls_, self.bbox_)\n",
    "        \n",
    "        anchors.append(anchor)\n",
    "        cls_preds.append(cls_pred)\n",
    "        bbox_preds.append(bbox_pred)\n",
    "        \n",
    "        anchors = torch.cat(anchors, dim = 1)\n",
    "        cls_preds = concat_preds1(cls_preds).reshape(self.batch_size, -1, self.num_classes + 1)\n",
    "        bbox_preds = concat_preds1(bbox_preds).reshape(self.batch_size, -1, self.num_anchors)\n",
    "        \n",
    "        return Y, anchors, cls_preds, bbox_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecafa76e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = TinySSD(num_anchors, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddcd6a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128, 32, 32]),\n",
       " torch.Size([1, 4096, 4]),\n",
       " torch.Size([2, 4096, 2]),\n",
       " torch.Size([2, 4096, 4]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2, 3, 256, 256))\n",
    "Y, anchors, cls_preds, bbox_preds = net(x)\n",
    "Y.shape, anchors.shape, cls_preds.shape, bbox_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28a8e9de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2080, -0.2080,  0.2392,  0.2392],\n",
       "         [-0.2451, -0.2451,  0.2764,  0.2764],\n",
       "         [-0.3006, -0.1425,  0.3319,  0.1737],\n",
       "         [-0.1425, -0.3006,  0.1737,  0.3319]]),\n",
       " tensor([[ 0.5675, -0.1531],\n",
       "         [-0.4040, -0.3229],\n",
       "         [ 0.2022, -0.3864],\n",
       "         [ 0.1109,  0.3222],\n",
       "         [-0.0512, -0.2267],\n",
       "         [-0.4944,  0.1246],\n",
       "         [ 0.3375, -0.1504],\n",
       "         [ 0.3743,  0.7429]], grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.6037, -0.1444,  0.4082, -0.4591],\n",
       "         [ 0.2632, -0.0634, -0.2583,  0.2985],\n",
       "         [-0.2412,  0.3440,  0.2798,  0.2658],\n",
       "         [-0.0413, -0.2419,  0.0119, -0.1481],\n",
       "         [-0.1401, -0.0223,  0.3051, -0.1466],\n",
       "         [-0.8708,  0.0743,  0.1341,  0.1062],\n",
       "         [-0.5684,  0.7054,  0.0756, -0.2449],\n",
       "         [-0.1126, -0.4281,  0.6010,  0.1057],\n",
       "         [-0.0811, -0.0665,  0.1183, -0.4917],\n",
       "         [-0.6865,  0.4111, -0.1646,  0.1088],\n",
       "         [ 0.1607,  0.2087,  0.4120, -0.1211],\n",
       "         [-0.3327, -0.2302,  0.2875, -0.0332],\n",
       "         [ 0.0021, -0.2039,  0.2445, -0.4784],\n",
       "         [-0.6012,  0.3636, -0.1506, -0.0810],\n",
       "         [-0.0542,  0.2026,  0.1900, -0.0370],\n",
       "         [-0.1789, -0.3240,  0.2066, -0.0330]], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors[0, 0:4], cls_preds[0, 0:8], bbox_preds[0, 0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e92ef513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x, y \u001b[38;5;241m=\u001b[39m all_data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), all_data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m Y, anchors, cls_preds, bbox_preds \u001b[38;5;241m=\u001b[39m net(x)\n\u001b[1;32m----> 3\u001b[0m \u001b[43massign_anchor_to_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36massign_anchor_to_bbox\u001b[1;34m(ground_truth, anchors, device, iou_threshold)\u001b[0m\n\u001b[0;32m     14\u001b[0m num_anchors, num_gt_boxes \u001b[38;5;241m=\u001b[39m anchors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], ground_truth\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m##计算锚框与真实框的iou,每一行是每一个锚框与所有真实框的iou\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m jaccard \u001b[38;5;241m=\u001b[39m \u001b[43mbox_iou\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#print(f\"jaccard:{jaccard}\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m##对于每个锚框，分配的真实边界框的张量,初始值均分配为-1，表示未分配真实边界框，长度为num_anchors,即锚框数量\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m##数据类型是torch.long是因为真实框的个数可能有很多.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m anchors_bbox_map \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((num_anchors, ), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong, device \u001b[38;5;241m=\u001b[39m device)\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mbox_iou\u001b[1;34m(boxes1, boxes2)\u001b[0m\n\u001b[0;32m     13\u001b[0m area2 \u001b[38;5;241m=\u001b[39m box_area(boxes2)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#注意:是boxes1与boxes2中的每个锚框都要计算交并比,并不是只计算对应行的锚框的交并比.这个要进行注意\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#找输入锚框boxes1和boxes2的左上角的最大的坐标,计算交并比.用了广播机制.\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m inter_upperleft \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboxes2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#找输入锚框boxes1和boxes2的右下角的最小坐标.用了广播机制.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m inter_lowerright \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(boxes1[:, \u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39munsqueeze(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m), boxes2[:, \u001b[38;5;241m2\u001b[39m:])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "x, y = all_data[0][0].unsqueeze(0), all_data[0][1]\n",
    "Y, anchors, cls_preds, bbox_preds = net(x)\n",
    "assign_anchor_to_bbox(y[1:].unsqueeze(0), anchors, anchors.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be2e9c",
   "metadata": {},
   "source": [
    "## 3 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ef591",
   "metadata": {},
   "source": [
    "### 3.1 加载香蕉数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2ccb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"C:/Users/CCU6/Desktop/数据集/banana-detection/banana-detection/bananas_train\"\n",
    "path_validtion = \"C:/Users/CCU6/Desktop/数据集/banana-detection/banana-detection/bananas_val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a2aa10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_banana_data(is_train = True, path_train = path_train, path_val = path_validtion):\n",
    "    if is_train:\n",
    "        image_path = path_train\n",
    "        csv_path = path_train + \"/label.csv\"\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        image_path = path_val\n",
    "        csv_path = path_val + \"/label.csv\"\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "    images, targets = [], []\n",
    "    for image_index, target in csv_data.iterrows():\n",
    "        images.append(torchvision.io.read_image(image_path + \"/images/\" + target[0]).float())\n",
    "        target[2:] = target[2:] / 256\n",
    "        targets.append(list(target[1:]))\n",
    "    \n",
    "    return images, torch.tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b02618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.4062, 0.0781, 0.5586, 0.2266])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, target = read_banana_data()\n",
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b3f1dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, is_train = True, transforms = None):\n",
    "        super().__init__()\n",
    "        self.images, self.labels = read_banana_data(is_train = is_train)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8ab0355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,\n",
       " (tensor([[[217., 223., 220.,  ...,  28.,  15.,  28.],\n",
       "           [206., 207., 215.,  ...,  41.,  18.,  29.],\n",
       "           [191., 197., 210.,  ...,  54.,  28.,  18.],\n",
       "           ...,\n",
       "           [205., 211., 207.,  ...,  44.,  50.,  75.],\n",
       "           [201., 202., 203.,  ...,  50.,  55.,  69.],\n",
       "           [198., 195., 198.,  ...,  55.,  59.,  68.]],\n",
       "  \n",
       "          [[214., 220., 219.,  ...,  23.,  10.,  23.],\n",
       "           [203., 207., 214.,  ...,  36.,  13.,  24.],\n",
       "           [191., 197., 210.,  ...,  46.,  23.,  13.],\n",
       "           ...,\n",
       "           [202., 208., 204.,  ...,  45.,  52.,  77.],\n",
       "           [197., 199., 200.,  ...,  52.,  57.,  72.],\n",
       "           [194., 191., 195.,  ...,  57.,  61.,  71.]],\n",
       "  \n",
       "          [[241., 249., 250.,  ...,  19.,   4.,  17.],\n",
       "           [230., 233., 245.,  ...,  32.,   7.,  18.],\n",
       "           [215., 223., 238.,  ...,  43.,  17.,   7.],\n",
       "           ...,\n",
       "           [221., 225., 221.,  ...,  37.,  39.,  63.],\n",
       "           [214., 216., 217.,  ...,  41.,  43.,  55.],\n",
       "           [209., 206., 212.,  ...,  46.,  47.,  54.]]]),\n",
       "  tensor([0.0000, 0.4062, 0.0781, 0.5586, 0.2266])))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = MyDataset(True)\n",
    "len(all_data), all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bce0ea00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train = torch.utils.data.DataLoader(MyDataset(True), batch_size = 128, shuffle = True, num_workers = 0)\\nval = torch.utils.data.DataLoader(MyDataset(False), batch_size = 128, shuffle = True, num_workers = 0)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"train = torch.utils.data.DataLoader(MyDataset(True), batch_size = 128, shuffle = True, num_workers = 0)\n",
    "val = torch.utils.data.DataLoader(MyDataset(False), batch_size = 128, shuffle = True, num_workers = 0)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd40538",
   "metadata": {},
   "source": [
    "### 3.2 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "babc0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "bbox_loss = nn.L1Loss(reduction='none')\n",
    "\n",
    "def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks, alpha = 1):\n",
    "    \"\"\"\n",
    "    输入分别是类别预测值,类别真实值,边界框偏移量预测值,边界框偏移量真实值,掩码变量.\n",
    "    \"\"\"\n",
    "    batch_size, num_classes = cls_preds.shape[0], cls_preds.shape[2]\n",
    "    cls = cls_loss(cls_preds.reshape(-1, num_classes),\n",
    "                   cls_labels.reshape(-1)).reshape(batch_size, -1).mean(dim=1)\n",
    "    bbox = bbox_loss(bbox_preds * bbox_masks, bbox_labels * bbox_masks).mean(dim=1)\n",
    "    return cls + alpha * bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbdb3c2",
   "metadata": {},
   "source": [
    "### 3.3 评估标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74b93387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_eval(cls_preds, cls_labels):\n",
    "    # 由于类别预测结果放在最后一维，argmax需要指定最后一维。\n",
    "    return float((cls_preds.argmax(dim=-1).type(cls_labels.dtype) == cls_labels).sum())\n",
    "\n",
    "def bbox_eval(bbox_preds, bbox_labels, bbox_masks):\n",
    "    return float((torch.abs((bbox_labels - bbox_preds) * bbox_masks)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e56f8",
   "metadata": {},
   "source": [
    "### 3.4 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49de1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, num_epochs, alpha, device, batch_size):\n",
    "    train_cls_his_acc = []\n",
    "    val_cls_his_acc = []\n",
    "    train_bbox_loss_his = []\n",
    "    val_bbox_loss_his = []\n",
    "    train = torch.utils.data.DataLoader(MyDataset(True), batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "    val = torch.utils.data.DataLoader(MyDataset(False), batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr = alpha, weight_decay = 5e-4)\n",
    "    net = net.to(device)\n",
    "    print(f\"train on: {device}\")\n",
    "    for i in range(num_epochs):\n",
    "        train_cls_acc = 0\n",
    "        train_bbox_loss = 0\n",
    "        net.train()\n",
    "        for image, target in train:\n",
    "            trainer.zero_grad()\n",
    "            X, Y = image.to(device), target.unsqueeze(1).to(device)\n",
    "            ##边界框，类别预测值(批量,锚框数,类别数带背景)，偏移量预测值(批量,锚框偏移量)\n",
    "            anchors, cls_preds, bbox_preds = net(X)\n",
    "            ##锚框与真实框偏移量(批量,锚框个数*4)，掩码(批量,锚框个数*4)，锚框类别(批量,锚框个数)\n",
    "            bbox_labels, bbox_masks, cls_labels = multibox_target(anchors, Y)\n",
    "            loss = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks)\n",
    "            loss.mean().backward()\n",
    "            trainer.step()\n",
    "            with torch.no_grad():\n",
    "                train_cls_acc = cls_eval(cls_preds, cls_labels) + train_cls_acc\n",
    "                train_bbox_loss = bbox_eval(bbox_preds, bbox_labels, bbox_masks) + train_bbox_loss\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            val_cls_acc = 0\n",
    "            val_bbox_loss = 0\n",
    "            for image, target in val:\n",
    "                X, Y = image.to(device), target.unsqueeze(1).to(device)\n",
    "                anchors, cls_preds, bbox_preds = net(X)\n",
    "                bbox_labels, bbox_masks, cls_labels = multibox_target(anchors, Y)\n",
    "                val_cls_acc = cls_eval(cls_preds, cls_labels) + val_cls_acc\n",
    "                val_bbox_loss = bbox_eval(bbox_preds, bbox_labels, bbox_masks) + val_bbox_loss\n",
    "        \n",
    "        train_cls_his_acc.append(train_cls_acc)\n",
    "        val_cls_his_acc.append(val_cls_acc)\n",
    "        train_bbox_loss_his.append(train_bbox_loss)\n",
    "        val_bbox_loss_his.append(val_bbox_loss)\n",
    "        plot_image(2, i, train_bbox_loss_his, val_bbox_loss_his, train_cls_his_acc, val_cls_his_acc)\n",
    "    #print(f\"train acc:{max(train_cls_his_acc)}, test acc:{max(val_cls_his_acc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535c171",
   "metadata": {},
   "source": [
    "### 3.5 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9173ce02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:5443000.0, test acc:544300.0\n"
     ]
    }
   ],
   "source": [
    "net = TinySSD(num_anchors, 1)\n",
    "device = torch.device(\"cuda:0\")\n",
    "num_epochs, alpha, batch_size = 50, 0.5, 32\n",
    "train(net, num_epochs, alpha, device, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0362702",
   "metadata": {},
   "source": [
    "## 4 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "264865f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = read_banana_data(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77752d9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " torch.Size([3, 256, 256]),\n",
       " torch.Size([100, 5]),\n",
       " tensor([[[36., 37., 38.,  ..., 18., 17., 17.],\n",
       "          [38., 38., 39.,  ..., 18., 18., 18.],\n",
       "          [38., 39., 40.,  ..., 19., 18., 18.],\n",
       "          ...,\n",
       "          [11.,  8.,  8.,  ...,  3.,  2.,  2.],\n",
       "          [10.,  8.,  7.,  ...,  3.,  2.,  2.],\n",
       "          [ 8.,  8.,  5.,  ...,  3.,  2.,  2.]],\n",
       " \n",
       "         [[30., 31., 31.,  ..., 21., 20., 20.],\n",
       "          [32., 32., 32.,  ..., 21., 21., 21.],\n",
       "          [32., 33., 34.,  ..., 22., 21., 21.],\n",
       "          ...,\n",
       "          [ 3.,  3.,  2.,  ...,  3.,  2.,  2.],\n",
       "          [ 4.,  4.,  3.,  ...,  3.,  2.,  2.],\n",
       "          [ 4.,  4.,  3.,  ...,  3.,  2.,  2.]],\n",
       " \n",
       "         [[34., 35., 38.,  ..., 26., 25., 25.],\n",
       "          [36., 36., 39.,  ..., 26., 26., 26.],\n",
       "          [36., 37., 38.,  ..., 27., 26., 26.],\n",
       "          ...,\n",
       "          [ 1.,  0.,  2.,  ...,  3.,  2.,  2.],\n",
       "          [ 4.,  3.,  4.,  ...,  3.,  2.,  2.],\n",
       "          [ 3.,  3.,  6.,  ...,  3.,  2.,  2.]]]),\n",
       " tensor([0.0000, 0.7148, 0.2461, 0.9414, 0.4375]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), X[0].shape, Y.shape, X[0], Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f1627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
